---
output: github_document
params:
  day: "Monday"
---

# Project 2: `r params$day` Data

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r libraries}
library(tidyverse)
library(caret)
library(modelr)
```

## Introduction: 

In this project I will be using the `OnlineNewsPopularity.csv` data, which is a data set about various articles that are published along with various article and publishing attributes.  The goal of this project is to accurately predict the number of times that a particular article will be "shared" on social media given its attributes.

The data set contains articles that are published on all 7 days of the week.  In this report, I will *only* be considering articles that were published on a **`r params$day`**.  In order to predict the number of shares, I will first build a Linear Regression model and then a Random Forest model on training data.  I will then compare the performance of both on a test data set and select the final predictive model. 

## Data Summary

```{r data_preprocess}
#Read in raw data
news <- read_csv("/Users/Saara/Documents/NC State/ST558/Project 2/Project2/Data/OnlineNewsPopularity.csv")

#Create day of week variable for parameters
news2 <- news %>% mutate(day = ifelse(weekday_is_monday==1, "Monday", 
                                      ifelse(weekday_is_tuesday==1, "Tuesday",
                                             ifelse(weekday_is_wednesday==1, "Wednesday", 
                                                    ifelse(weekday_is_thursday==1, "Thursday",
                                                           ifelse(weekday_is_friday==1, "Friday",
                                                                  ifelse(weekday_is_saturday==1, "Saturday", "Sunday")))))))

#Convert day to a factor
news2$day <- as.factor(news2$day)

dim <- dim(news2)
```

```{r subset}
# Create the subset of data that equals the correct parameter
news_subset <- news2 %>% filter(day == params$day)
dim2 <- dim(news_subset)

#Delete variables that are non-predictive
final_subset <- news_subset %>% select(-url, -timedelta, -starts_with("weekday_is"), -day, -starts_with("LDA"), -is_weekend)
dim3 <- dim(final_subset)
```

Overall, the Online News Popularity data has *`r dim[1]`* observations and *`r dim[2]`* variables.  There are a total of *`r dim2[1]`* observations for articles that were published on a `r params$day`, and that is the subset of observations that I will be using for this report.  From the initial variables, I will be considering *`r dim3[2]`* of them as potentially having an effect on number of shares.

There are 5 groups of variables that have similar themes in this data set. The variables within each group likely have high correlations with each other. The variable groups are about:

  1.  Number of words/keywords/media
  
  2. Digital channel type
  
  3. Shares by keyword
  
  4. Typical shares of articles in Mashable
  
  5. Sentiment and Polarity

**Correlation Plots for Number of Word Variables:**

As seen below, many of the variables are highly correlated and might need to be removed.

```{r Var_Explore}
#Group 1
num <- final_subset %>% select(starts_with("n_"), starts_with("num"), average_token_length)
pairs(num)
```

**Data Channel Type:**

A correlation plot of the data channel variables shows that each of them is mutually exclusive and therefore can be considered dummy variables for one categorical variable.

```{r Var_Explore2}
# final_subset <- final_subset %>% mutate(d_channel = ifelse(data_channel_is_lifestyle==1, "lifestyle", 
#                                       ifelse(data_channel_is_entertainment==1, "entertainment",
#                                              ifelse(data_channel_is_bus==1, "business", 
#                                                     ifelse(data_channel_is_socmed==1, "social media",
#                                                            ifelse(data_channel_is_tech==1, "tech", "world")))))) %>% select(-starts_with("data_channel"))
# 
# final_subset$d_channel <- as_factor(final_subset$d_channel) 
# summary(final_subset$d_channel)
```


**Shares by Keyword Variables:**

As seen below, many of the variables seem correlated and might need to be removed.

```{r Var_Explore3}

kw <- final_subset %>% select(starts_with("kw"))
pairs(kw)
```

**Mashable Shares Variables:**

These variables seem to have very similar distributions. It is not clear whether there will be any relationship with overall shares.

```{r Var_Explore4}

mash <- final_subset %>% select(starts_with("self"), shares)
pairs(mash)
```

**Sentiment/Polarity Variables:**

When comparing variables measuring positive and negative polarities, there seems to be moderate to strong correlations.

```{r Var_Explore5}
pos <- final_subset %>% select(contains("positive"))
pairs(pos)

neg <- final_subset %>% select(contains("negative"))
pairs(neg)
```

## Modeling

First, I will split the data into training and test sets.  The training data set will contain 70% of the data observations, and the test set will contain the remaining 30%.

Dimensions of the train and test sets: 

```{r data_split}
set.seed(100)
train <- sample(1:nrow(final_subset), size = nrow(final_subset)*0.7)
test <- setdiff(1:nrow(final_subset), train)

dTrain <- final_subset[train, ]
dTest <- final_subset[test, ]

dim(dTrain)
dim(dTest)
```

### Linear Model

I will first begin by fitting a linear regression model with ALL of the variables.  

Here is the summary of the first linear model.  Looking at the t statistics and p-values, the majority of predictors are not statistically significant for predicting shares.  The model overall is statistically significant, but has an incredibly low adjusted-R^2^ value (0.0239).

```{r Lin1}
Lin1 <- lm(shares~., data = dTrain)
summary(Lin1)
```

I will now update the linear regression model, only including the statistically significant predictors. Hopefully this will increase the predictivity of the model.

Here is the summary for the second iteration of the model.  The adjusted-R^2^ still is low despite the majority of the predictors being statistically significant now.
```{r Lin2}
Lin2 <- lm(shares~data_channel_is_entertainment + kw_min_min + kw_max_max + kw_avg_max + kw_max_avg + kw_avg_avg + min_positive_polarity, data=dTrain)
summary(Lin2)
```

Looking at the plots for the model, it seems that there are leverage points affecting the predictions.
```{r}
#plots for linear fit
par(mfrow=c(2,2))
plot(Lin2)
```

I will now remove the leverage points and create the final linear model.  As seen below, the adjusted R^2^ has improved a bit for about a 6% explanation of variability, but the RSE has reduced quite a bit.  I am assuming that a non-linear model will perform much better for this prediction.

```{r Leverage}
#Remove leverage points
w <- abs(rstudent(Lin2)) < 3 & abs(cooks.distance(Lin2)) < 4/nrow(Lin2$model)
Lin4 <- update(Lin2, weights=as.numeric(w))
summary(Lin4)
```


### Non-Linear Models

First, I will fit a simple Regression Tree in order to predict shares.  Here is the code below:

```{r tree_train, echo=TRUE}
set.seed(100)
trctrl <- trainControl(method="repeatedcv", number=10, repeats = 3)
metric = 'RMSE'
tree_fit <- train(shares ~., data = dTrain, method = "rpart", metric = metric, trControl = trctrl,
                 preProcess = c("center", "scale") )
```


I will also fit a bagged tree to predict shares.  Here is the code for that:

```{r bag_train, echo=TRUE}
bag_fit <- train(shares ~., data = dTrain, method = "treebag", metric = metric, trControl = trctrl,
                 preProcess = c("center", "scale") )
```


## Test Set Prediction

I will fit each of the 3 models (Linear Regression, Regression Tree, Bagged Tree) on the test data set.

```{r test}
#Linear Regression
Lin_test <- predict(Lin4, newdata = dTest)
#Regression Tree
tree_test <- predict(tree_fit, newdata = dTest)
#Bagged Tree
bag_test <- predict(bag_fit, newdata = dTest)
```


```{r rmse}
rmse_lin <- sqrt(mean((Lin_test - dTest$shares)^2))
rmse_tree <- sqrt(mean((tree_test - dTest$shares)^2))
rmse_bag <- sqrt(mean((bag_test - dTest$shares)^2))

# rmse_lin
# rmse_tree
# rmse_bag
```

Here are the corresponding RMSE values:

* The RMSE for the Linear Regression model on the test set is `r rmse_lin`.

* The RMSE for the Regression Tree model on the test set is `r rmse_tree`.

* The RMSE for the Bagged Tree model on the test set is `r rmse_bag`.


## Conclusion

Comparing the linear and non-linear methods based on test MSE, the Linear Regression model performed the best in predicting number of shares, despite having a high MSE and low adjusted R^2^ on its own.