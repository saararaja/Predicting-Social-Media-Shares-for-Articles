---
output: github_document
params:
  day: "Monday"
---

# Project 2: `r params$day` Data

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, cache = FALSE)
```

```{r libraries}
library(tidyverse)
library(caret)
```

## Introduction: 

In this project I will be using the `OnlineNewsPopularity.csv` data, which is a data set about various articles that are published along with various article and publishing attributes.  The goal of this project is to accurately predict the number of times that a particular article will be "shared" on social media given its attributes.

The data set contains articles that are published on all 7 days of the week.  In this report, I will *only* be considering articles that were published on a **`r params$day`**.  In order to predict the number of shares, I will first build a Linear Regression model and then a Random Forest model on training data.  I will then compare the performance of both on a test data set and select the final predictive model. 

## Data Summary

```{r data_preprocess}
#Read in raw data
news <- read_csv("/Users/Saara/Documents/NC State/ST558/Project 2/Project2/Data/OnlineNewsPopularity.csv")

#Create day of week variable for parameters
news2 <- news %>% mutate(day = ifelse(weekday_is_monday==1, "Monday", 
                                      ifelse(weekday_is_tuesday==1, "Tuesday",
                                             ifelse(weekday_is_wednesday==1, "Wednesday", 
                                                    ifelse(weekday_is_thursday==1, "Thursday",
                                                           ifelse(weekday_is_friday==1, "Friday",
                                                                  ifelse(weekday_is_saturday==1, "Saturday", "Sunday")))))))

#Convert day to a factor
news2$day <- as.factor(news2$day)

dim <- dim(news2)
```

```{r subset}
# Create the subset of data that equals the correct parameter
news_subset <- news2 %>% filter(day == params$day)
dim2 <- dim(news_subset)

#Delete variables that are non-predictive
final_subset <- news_subset %>% select(-url, -timedelta, -starts_with("weekday_is"), -day, -starts_with("LDA"), -is_weekend)
dim3 <- dim(final_subset)
```

Overall, the Online News Popularity data has *`r dim[1]`* observations and *`r dim[2]`* variables.  There are a total of *`r dim2[1]`* observations for articles that were published on a `r params$day`, and that is the subset of observations that I will be using for this report.  From the initial variables, I will be considering *`r dim3[2]`* of them as potentially having an effect on number of shares.

There are 5 groups of variables that have similar themes in this data set. The variables within each group likely have high correlations with each other. The variable groups are about:

  1.  Number of words/keywords/media
  
  2. Digital channel type
  
  3. Shares by keyword
  
  4. Typical shares of articles in Mashable
  
  5. Sentiment and Polarity

**Correlation Plots for Number of Word Variables:**

As seen below, many of the variables are highly correlated and might need to be removed.

```{r Var_Explore}
#Group 1
num <- final_subset %>% select(starts_with("n_"), starts_with("num"), average_token_length)
pairs(num)
```

**Data Channel Type:**

A correlation plot of the data channel variables shows that each of them is mutually exclusive and therefore can be considered dummy variables for one categorical variable.

```{r Var_Explore2}
# final_subset <- final_subset %>% mutate(d_channel = ifelse(data_channel_is_lifestyle==1, "lifestyle", 
#                                       ifelse(data_channel_is_entertainment==1, "entertainment",
#                                              ifelse(data_channel_is_bus==1, "business", 
#                                                     ifelse(data_channel_is_socmed==1, "social media",
#                                                            ifelse(data_channel_is_tech==1, "tech", "world")))))) %>% select(-starts_with("data_channel"))
# 
# final_subset$d_channel <- as_factor(final_subset$d_channel) 
# summary(final_subset$d_channel)
```


**Shares by Keyword Variables:**

As seen below, many of the variables seem correlated and might need to be removed.

```{r Var_Explore3}

kw <- final_subset %>% select(starts_with("kw"))
pairs(kw)
```

**Mashable Shares Variables:**

These variables seem to have very similar distributions. It is not clear whether there will be any relationship with overall shares.

```{r Var_Explore4}

mash <- final_subset %>% select(starts_with("self"), shares)
pairs(mash)
```

**Sentiment/Polarity Variables:**

When comparing variables measuring positive and negative polarities, there seems to be moderate to strong correlations.

```{r Var_Explore5}
pos <- final_subset %>% select(contains("positive"))
pairs(pos)

neg <- final_subset %>% select(contains("negative"))
pairs(neg)
```

## Modeling

First, I will split the data into training and test sets.  The training data set will contain 70% of the data observations, and the test set will contain the remaining 30%.

Dimensions of the train and test sets: 

```{r data_split}
set.seed(100)
train <- sample(1:nrow(final_subset), size = nrow(final_subset)*0.7)
test <- setdiff(1:nrow(final_subset), train)

dTrain <- final_subset[train, ]
dTest <- final_subset[test, ]

dim(dTrain)
dim(dTest)
```

### Linear Model

I will first begin by fitting a linear regression model with ALL of the variables.  

Here is the summary of the first linear model.  Looking at the t statistics and p-values, the majority of predictors are not statistically significant for predicting shares.  The model overall is statistically significant, but has an incredibly low adjusted-R^2^ value (0.0239).

```{r Lin1}
Lin1 <- lm(shares~., data = dTrain)
summary(Lin1)
```

I will now update the linear regression model, only including the statistically significant predictors. Hopefully this will increase the predictivity of the model.

```{r Lin2}
Lin2 <- lm(shares~data_channel_is_entertainment + kw_min_min + kw_max_max + kw_avg_max + kw_max_avg + kw_avg_avg + min_positive_polarity, data=dTrain)
summary(Lin2)

#plots for linear fit
par(mfrow=c(2,2))
plot(Lin2)
```


Quadratic did not work
```{r}
Lin3 <- lm(shares~data_channel_is_entertainment + kw_min_min + I(kw_min_min^2) + kw_max_max + I(kw_max_max^2) + kw_avg_max + I(kw_avg_max^2) + kw_max_avg + I(kw_max_avg^2) + kw_avg_avg + I(kw_avg_avg^2), data=dTrain)
summary(Lin3)
```


```{r Leverage}
plot(hatvalues(Lin2))
which.max(hatvalues(Lin2))

#Remove leverage points
w <- abs(rstudent(Lin2)) < 3 & abs(cooks.distance(Lin2)) < 4/nrow(Lin2$model)
Lin4 <- update(Lin2, weights=as.numeric(w))
summary(Lin4)

par(mfrow=c(2,2))
plot(Lin4)
```


### Non-Linear Model

```{r tree_train, echo=TRUE}
set.seed(100)
trctrl <- trainControl(method="repeatedcv", number=10)

tree_fit <- train(shares ~., data = dTrain, method = "rpart", trControl = trctrl,
                 preProcess = c("center", "scale") )

summary(tree_fit)
```


### Bagged Tree

I will fit the bagged tree with the code below.  The method is specified to `treebag`.

```{r bag_train, echo=TRUE}
bag_fit <- train(shares ~., data = dTrain, method = "treebag", trControl = trctrl,
                 preProcess = c("center", "scale") )

summary(bag_fit)
```

### Random Forest

I will fit the random forest with the code below.  The method is specified to `rf`.

```{r rf_train, echo=TRUE}
rf_fit <- train(shares ~., data = dTrain, method = "rf", trControl = trctrl,
                 preProcess = c("center", "scale") )

summary(rf_fit)
```

### Boosted Tree

I will fit the boosted tree with the code below.  The method is specified to `gbm`.

```{r boost_train, echo=TRUE}
boost_fit <- train(shares ~., data = dbTrain, method = "gbm", trControl = trctrl,
                 preProcess = c("center", "scale"), verbose=FALSE )

summary(boost_fit)
```

